# Personalized Book Recommendation App (ReadDNA)

My personalizaed book reomendation app, ReadDNA, helps readers discover new books based on their reading preferences entered in my user quiz. Instead of recommending only popular titles it tries to recommend hidden gems that the user will love! 

## Problem

Those who love to read often find it challenging to find new books to read due to the number of
books out there to choose from. Many of which could align with the readers’ preferences but may
not be popular. Existing recommendation systems often suggest generic bestsellers rather than
truly personalized recommendations. My project aims to develop a personalized book
recommender that provides tailored suggestions based on a reader’s favorite titles and reading
history.

## Previous Efforts

There are several book recommendation systems that exist. Most notably the ones used by
platforms like Google Books, Amazon, and Goodreads. But these systems often have a position bias
and recommend already popular titles. My system prioritizes unpopular items to help users discover
hidden gems.

## Datasets
This project uses the publicly available Amazaon reviews dataset and I took a random sample of 50,000 datapoints from the dataset:

### Amazon Books Reviews Dataset
- Contains over 3 million reviews from Amazon users on over 200,000 books
- Includes review scores, text reviews, user IDs, and book titles
- Useful for modeling user preferences and behavior

## Data pipeline
    1. Data Loading and Cleaning: First I took the data from the Amazon reviews dataset aswell as the metadata and did some cleaning such as standardizing columns, removing duplicates, and lowercased entries to ensure consistency.
    2. Feature Engineering: I added a helpfulness score based on amazon reviews calculated as upvotes/total votes and then selected the 5 most helpful reviews for each book to keep as context for the deep learning model.
    3. The full dataset has over 200,000 books. Therefore, I sampled 50,000 books to keep it more managable while still having a diverse dataset of books generes and popularity levels.
    4. For the Classical ML approach, I used just the book titles to create a TF-IDF matrix of titles and saved the maxtrix and filtered vectorizer. 
    5. For the deep learning model, each book's title, description, and top 5 reviews were combined into one text string and turned into a vector using the MPNet SentenceTransformer.
    6. The embeddings were generated in batches using sentence-transformers and saved as npy files. These were stored in 'hybrid_book_embeddings.npy' and I built an FAISS index for fast similarity search for the application.
    7. The final datasets used to train my models are too large for github and are hosted on hugging face:
[Hugging Face Datasets](https://huggingface.co/datasets/JesseFWarrenV/BookRecommender/tree/main)

## Approaches

### 1. Naive Model
Recommends top-rated books across the board, regardless of user preferences.

### 2. Classical ML Model (TF-IDF + Cosine Similarity)
For my classical ML model I used a content based filtering approach using TF-IDF vectorization of book titles and cosine similarity to find books with similar names.

### 3. Deep Learning Model (Transformer + FAISS)
For this model, I used a transformer (MPNet) to embed each book based on its title, description, and a few of its most helpful reviews, turning it into a vector. I use FAISS to search through those embeddings and find similar books to the input query consisting of the user's quiz asnwers in my frontend application. This lets the system go beyond just ratings, recommending books that feel similar, even if they aren’t super popular.  
The final models for this approach were too large for github and are stored on hugging face:
[Hugging Face Datasets](https://huggingface.co/datasets/JesseFWarrenV/BookRecommender/tree/main)

## Demo
My application is deployed on Render and is availble here:  
[ReadDNA on Render](https://bookrecommender-79xd.onrender.com/)  
[Video](https://www.youtube.com/watch?v=LUeKba449G4)  

## Model Evaluation Strategy
To evaluate my models I tested them using 3 well known books: Harry Potter and the Sorcerer's Stone, The Hobbit, and The Great Gatsby. Then I compared the quality and relevance of the recommendations generated by each approach.   
1. Naive Approach    
    This approach always generated top rated books in the dataset. Although they are popular books and may be liked by users, it has little to do with the user query.   
2. Classical ML Approach:  
    This model uses TF-IDF and Cosine similarity on titles.   
    -For Harry Potter, it returns other Harry potter related titles.  
    -For the Hobbit, it returns poems from the hobbit, Tolkien themed study guides, and some random titles.  
    -For the Great Gatsby, it recommends different versions of the Great Gatsby and other titles with the word "Great" in it.  
3. Deep Learning Approach:  
    -For Harry Potter, it suggested more Harry Potter books, and similar fantasty series.  
    -For The Hobbit, it suggested other fantasty stories and mythological content.  
    -For The Great Gatsby, it returned works related to American Literature.  

In conclusion, the deep learning model performs the best in terms of relevant recommendation and quality. Likely do to the addition of semantic similarity versus only looking at the book title. While the classical model offers a more lightweight recommendation alternative while giving relatively good recommendations. Lastly, the naive model is really only useful as a baseline but shows that both the classical and deep learning models are working much better than the baseline.  

## Results and Conclusion
Out of the 3 models I built and tested, the deep learning model using MPNet embeddings and FAISS gave the most consistent and meaningful reocmmendations. This model was able to recommend books that were similar by thematic elements and genre.  

This project demonstrated how combinging NLP techniques with structured metadata and user preferences enables a more personalized book recommendation experience. I wish to keep working on and improving this project and in the future I would like to:

-Include more book titles
-Use more data to train the model
-Add user feedback for continued updates
-Fine tune the sentance transformer on book review data for better embeddings

## Project Structure

```
BookRecommender/
│
├── backend/                     # Flask backend
│   ├── app.py                   # Main Flask application
│   └── requirements.txt         # Python dependencies
│
├── scripts/                     # All modeling and preprocessing scripts
│   ├── classical_ml_model.py    # TF-IDF Content Based filtering model
│   ├── deep_learning.py         # Deep model that uses sentence transformers to embed and save vectors
│   ├── merge_embeddings.py      # I created the embeddings in batches to save progress, this script just merges everything at the end
│   ├── faiss_embeddings.py      # FAISS index creation
│   ├── naive_model.py           # Naive top-rated book recommender
│   ├── top10_classical.csv      # Sample output from classical model
│   └── top10_naive.csv          # Sample output from naive model
│
├── data/                        # Metadata and subset CSVs (These datasets were used for initial modeling with smaller subsets of data.
|   |                              The datasets used to train the final models are hosted here on hugging face: 
|   |                              https://huggingface.co/datasets/JesseFWarrenV/BookRecommender/tree/main)
│   ├── books.csv                
│   └── books_subset.csv
│
├── models/                      # Models created: Final models for the deep learning approach were too large and are stored on hugging face:
|   |                              (https://huggingface.co/datasets/JesseFWarrenV/BookRecommender/tree/main)
│   ├── tfidf_matrix.npz         # Sparse matrix of TF-IDF embeddings for all book titles
│   ├── tfidf_vectorizer.pkl     # Saved TF-IDF vectorizer used to transform book titles into vectors (classical model)
│   │                            # The files below were created on a smaller subset of the dataset for testing. Final versions are on hugging face
│   ├── hybrid_book_ids_subset.npy   # Numpy array of book titles that correspond to the deep model embeddings
│   ├── hybrid_book_embeddings_subset.npy # Dense MPNet-generated embeddings of books (title + description + reviews)
│   └── faiss_index_subset.idx      # FAISS index built from the hybrid embeddings for fast similarity search (deep model)
│
├── frontend/                    # React frontend
│   └── src/
│       ├── components/          # Navbar and Footer for frontend
│       ├── pages/               # Home page, Book search page, UserPreferences quiz page, and Recommendations page
│       └── App.tsx              # App layout and routing
│
├── .gitignore
└── README.md
```

## Ethics Statement
ReadDNA uses data from Goodreads, Amazon, and Google Books, which can introduce some bias. A few things to keep in mind:

- Popular books are shown more often than niche or indie ones
- Underrepresented authors and genres might get overlooked
- Collaborative filtering can overfit to the majority’s tastes

I am hoping to improve this by:
- Using more diverse datasets
- Letting users control things like diversity in their recommendations

## How to run locally

1. Install requirements:  
    run 'cd backend'  
    run 'pip install -r requirements.txt'  
2. Start the backend:  
    run 'python app.py'  
3. Start the frontend:  
    run 'cd frontend'  
    run 'npm install'  
    run 'npm start'     